{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Results Analysis for Qualtrics Python Skill Level Survey\n",
    "\n",
    "This document provides a high-level analysis of the results from the Qualtrics Python Skill Level Survey. The goal of the survey was to objectively assess the Python skill levels of participants, by placing them into one of the 2 categories: _Beginner_/_Novices_ and _Advanced_/_Experts_. \n",
    "\n",
    "The ultimate goal is to identify the best subset of questions that can effectively differentiate between these two skill levels. The actual content of the survey is centered around several aspects of Python programming error messages, and debugging techniques. The underlying assumption is that individuals with more experience in Python (and perhaps even general programming experience) will have a better understanding of error identification, resolution, and debugging strategies.\n",
    "\n",
    "The actual metrics that are captured in this analysis include:\n",
    "- **Completion Rate**: The percentage of participants who started and completed the survey.\n",
    "- **Average duration**: The average time (in seconds) taken by participants to complete the survey.\n",
    "- **Median duration**: The median time (in seconds) taken by participants to complete the survey.\n",
    "- **Average Python YoE**: The average number of years of experience participants have with Python.\n",
    "- **Average Programming YoE**: The average number of years of experience participants have with programming in general.\n",
    "- **Average Self-reported score**: The average self-reported score of correctly answered questions (out of 16 questions).\n",
    "- **Correlation between self-reported score and Python YoE**: The correlation coefficient between the self-reported correct answers score and the number of years of experience with Python.\n",
    "- **Correlation between self-reported score and Programming YoE**: The correlation coefficient between the self-reported correct answers score and the number of years of experience with programming in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the path to the Qualtrics CSV file (adjust as needed, but default is in the same directory)\n",
    "file_path = \"./qualtrics_responses_labels_simplified.csv\"\n",
    "\n",
    "# 1. Load data (Qualtrics exports are semicolonâ€‘delimited by default)\n",
    "df = pd.read_csv(file_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Required Libraries\n",
    "\n",
    "Prior to running the analysis, ensure that the required libraries are installed. For this, you need only install the libraries defined in the `requirements.txt` file. You can do this by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: ipython==9.2.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: decorator in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from ipython==9.2.0->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from Jinja2==3.1.6->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython==9.2.0->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython==9.2.0->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython==9.2.0->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from stack_data->ipython==9.2.0->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from stack_data->ipython==9.2.0->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/amoraru/Documents/GitHub/EXCEED/exceed-python-skill-assessment/.venv/lib/python3.12/site-packages (from stack_data->ipython==9.2.0->-r requirements.txt (line 2)) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data\n",
    "\n",
    "We need to load the survey response data from a CSV file, prior to performing any sort of analysis. Default file name should not be changed unless you have a different file name for the survey results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the path to the Qualtrics CSV file (adjust as needed, but default is in the same directory)\n",
    "file_path = \"./qualtrics_responses_labels_simplified.csv\"\n",
    "\n",
    "# 1. Load data (Qualtrics exports are semicolonâ€‘delimited by default)\n",
    "df = pd.read_csv(file_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Keep Only Completed Surveys\n",
    "\n",
    "In the dataset, it is possible to encounter entries of respondents that have started but not completed the survey within the allowed 2 weeks timeframe on Qualtrics. The following step filters out these incomplete surveys, ensuring that only fully completed responses are analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Keep only respondents who finished the survey\n",
    "completed = df[df[\"Finished\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze the Data\n",
    "\n",
    "This step calculates the metrics defined in the introduction to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate the required metrics\n",
    "metrics = {\n",
    "    \"Total number of responses\": len(df),\n",
    "    \"Total number of completed responses\": len(completed),\n",
    "    \"CompletionÂ rateÂ (%)\": round(df[\"Finished\"].mean() * 100, 2),\n",
    "    \"AverageÂ durationÂ (sec)\": completed[\"Duration (in seconds)\"].mean(),\n",
    "    \"Median durationÂ (sec)\": completed[\"Duration (in seconds)\"].median(),\n",
    "    \"AverageÂ PythonÂ experienceÂ (years)\": completed[\"Q2.2\"].mean(),\n",
    "    \"AverageÂ generalÂ experienceÂ (years)\": completed[\"Q2.3\"].mean(),\n",
    "    \"AverageÂ estimatedÂ correctÂ answers\": completed[\"Q11.1\"].mean(),\n",
    "    # Some correlations\n",
    "    \"Pearson CorrelationÂ (Python YoE and General programming YoE)\": completed[[\"Q2.2\", \"Q2.3\"]].corr().iloc[0, 1],\n",
    "    \"Spearman Correlation (Python YoE and self-reported score)\": completed[[\"Q2.2\", \"Q11.1\"]].corr(method='spearman').iloc[0, 1],\n",
    "    \"Spearman Correlation (General programming YoE and self-reported score)\": completed[[\"Q2.3\", \"Q11.1\"]].corr(method='spearman').iloc[0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate the Report\n",
    "\n",
    "This step creates a summary report of the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d2353\">\n",
       "  <caption>Qualtrics Python Skill Level Assessment - High-level Metrics</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d2353_level0_col0\" class=\"col_heading level0 col0\" >Metric</th>\n",
       "      <th id=\"T_d2353_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d2353_row0_col0\" class=\"data row0 col0\" >Total number of responses</td>\n",
       "      <td id=\"T_d2353_row0_col1\" class=\"data row0 col1\" >70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d2353_row1_col0\" class=\"data row1 col0\" >Total number of completed responses</td>\n",
       "      <td id=\"T_d2353_row1_col1\" class=\"data row1 col1\" >57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d2353_row2_col0\" class=\"data row2 col0\" >CompletionÂ rateÂ (%)</td>\n",
       "      <td id=\"T_d2353_row2_col1\" class=\"data row2 col1\" >81.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d2353_row3_col0\" class=\"data row3 col0\" >AverageÂ durationÂ (sec)</td>\n",
       "      <td id=\"T_d2353_row3_col1\" class=\"data row3 col1\" >27860.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d2353_row4_col0\" class=\"data row4 col0\" >Median durationÂ (sec)</td>\n",
       "      <td id=\"T_d2353_row4_col1\" class=\"data row4 col1\" >1007.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d2353_row5_col0\" class=\"data row5 col0\" >AverageÂ PythonÂ experienceÂ (years)</td>\n",
       "      <td id=\"T_d2353_row5_col1\" class=\"data row5 col1\" >5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d2353_row6_col0\" class=\"data row6 col0\" >AverageÂ generalÂ experienceÂ (years)</td>\n",
       "      <td id=\"T_d2353_row6_col1\" class=\"data row6 col1\" >12.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d2353_row7_col0\" class=\"data row7 col0\" >AverageÂ estimatedÂ correctÂ answers</td>\n",
       "      <td id=\"T_d2353_row7_col1\" class=\"data row7 col1\" >12.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d2353_row8_col0\" class=\"data row8 col0\" >Pearson CorrelationÂ (Python YoE and General programming YoE)</td>\n",
       "      <td id=\"T_d2353_row8_col1\" class=\"data row8 col1\" >0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d2353_row9_col0\" class=\"data row9 col0\" >Spearman Correlation (Python YoE and self-reported score)</td>\n",
       "      <td id=\"T_d2353_row9_col1\" class=\"data row9 col1\" >0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2353_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d2353_row10_col0\" class=\"data row10 col0\" >Spearman Correlation (General programming YoE and self-reported score)</td>\n",
       "      <td id=\"T_d2353_row10_col1\" class=\"data row10 col1\" >0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1127e5910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# 4. Present results in a tidy table\n",
    "summary_df = pd.DataFrame(list(metrics.items()), columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "display(summary_df.style.set_caption(\"Qualtrics Python Skill Level Assessment - High-level Metrics\").format(precision=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
